---
title: "Parallel"
format: html
---

---
title: "Practical One"
format: html
---

## Packages

```{r}
library(foreach)
library(doParallel)
library(MASS)
library(boot)
library(iterators)
library(parallel)
library(microbenchmark)
library(knitr)

```

## Question 1

```{r}
numCores = detectCores() -1
cl <- makeCluster(numCores)
registerDoParallel(numCores)
n <- 100

results <- foreach(i = 1:n, .combine = rbind, .packages = "stats") %dopar% {
  sample_d <- rexp(100, rate = 1)
  mean_s <- mean(sample_d)
  var_s <- var(sample_d)
  c(mean_s, var_s)
}
stopCluster(cl)

result_df <- as.data.frame(results)
colnames(result_df) <- c("Mean", "Variance")
head(result_df)

```

## Question 2

First setting the number of bootstrap samples = 1000 and trying chunk sizes of 100 and 1000 respectively. Note that the first few results from the bootstrap are displayed to show that they are yeilding plausible output.
```{r}
numCores <- detectCores() - 1
cl <- makeCluster(numCores)
registerDoParallel(cl)

numBootstraps <- 1000
chunkSize <- 100

#Parralel bootstrapping
system.time({
  boot_parallel <- foreach(i = 1:numBootstraps, .combine = c, .packages = "MASS") %dopar% {
    samp_med <- median(sample(galaxies, replace = TRUE))
    samp_med
  }
})

# Serial Bootstrapping
system.time({
  boot_serial <- sapply(1:numBootstraps, function(i) median(sample(galaxies, replace = TRUE)))
})

# Chunked Parallel Bootstrapping
system.time({
  boot_chunked <- foreach(i = 1:(numBootstraps/chunkSize), .combine = c, .packages = "MASS") %dopar% {
    replicate(chunkSize, median(sample(galaxies, replace = TRUE))) 
  }
})

stopCluster(cl)

head(boot_parallel)
head(boot_serial)
head(boot_chunked)

chunkSize <- 1000

system.time({
  boot_parallel <- foreach(i = 1:numBootstraps, .combine = c, .packages = "MASS") %dopar% {
    samp_med <- median(sample(galaxies, replace = TRUE))
    samp_med
  }
})

# Serial Bootstrapping
system.time({
  boot_serial <- sapply(1:numBootstraps, function(i) median(sample(galaxies, replace = TRUE)))
})

# Chunked Parallel Bootstrapping
system.time({
  boot_chunked <- foreach(i = 1:(numBootstraps/chunkSize), .combine = c, .packages = "MASS") %dopar% {
    replicate(chunkSize, median(sample(galaxies, replace = TRUE)))
  }
})

stopCluster(cl)

head(boot_parallel)
head(boot_serial)
head(boot_chunked)

```

Now setting the number of bootstrap samples = 10000 and testing across the same chunk sizes.
```{r}
numBootstraps <- 10000
chunkSize <- 100

#Parralel bootstrapping
system.time({
  boot_parallel <- foreach(i = 1:numBootstraps, .combine = c, .packages = "MASS") %dopar% {
    samp_med <- median(sample(galaxies, replace = TRUE))
    samp_med
  }
})

# Serial Bootstrapping
system.time({
  boot_serial <- sapply(1:numBootstraps, function(i) median(sample(galaxies, replace = TRUE)))
})

# Chunked Parallel Bootstrapping
system.time({
  boot_chunked <- foreach(i = 1:(numBootstraps/chunkSize), .combine = c, .packages = "MASS") %dopar% {
    replicate(chunkSize, median(sample(galaxies, replace = TRUE))) 
  }
})

stopCluster(cl)

head(boot_parallel)
head(boot_serial)
head(boot_chunked)

chunkSize <- 1000

system.time({
  boot_parallel <- foreach(i = 1:numBootstraps, .combine = c, .packages = "MASS") %dopar% {
    samp_med <- median(sample(galaxies, replace = TRUE))
    samp_med
  }
})

# Serial Bootstrapping
system.time({
  boot_serial <- sapply(1:numBootstraps, function(i) median(sample(galaxies, replace = TRUE)))
})

# Chunked Parallel Bootstrapping
system.time({
  boot_chunked <- foreach(i = 1:(numBootstraps/chunkSize), .combine = c, .packages = "MASS") %dopar% {
    replicate(chunkSize, median(sample(galaxies, replace = TRUE)))
  }
})

stopCluster(cl)

head(boot_parallel)
head(boot_serial)
head(boot_chunked)
```

## Question 3

```{r}
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)

boot_mean <- function(data, indices) {
  return(mean(data[indices]))
}

set.seed(123)
n_sim <- 1000
n_samp <- 50
alpha <- 0.05

# Run simulations in parallel
results <- foreach(i = 1:n_sim, .combine = c, .packages = "boot") %dopar% {
  samp_data <- rexp(n_samp, rate = 1)  # Mean is 1
  boot_res <- boot(samp_data, statistic = boot_mean, R = 1000)
  ci <- boot.ci(boot_res, type = "perc")$percent[4:5]
  (ci[1] <= 1) & (ci[2] >= 1)
}

stopCluster(cl)

cov_prob <- mean(results)
print(paste("Estimated Coverage:", round(cov_prob, 3)))

```

## Question 4

```{r,}
library(foreach)
library(iterators)

set.seed(1000)

iterat <- irnorm(3, 5)


max_vals <- foreach(vec = iterat, .combine = c) %do% {
  max(vec)
}

print(max_vals)

```

## Question 5

```{r,}
library(parallel)
library(foreach)
library(iterators)
library(microbenchmark)

set.seed(1234)

n_iters <- 1000
vec_size <- 5


generate_max <- function() {
  max(rnorm(vec_size))
}

replicate_test <- function() {
  replicate(n_iters, generate_max())
}

foreach_test <- function() {
  foreach(i = 1:n_iters, .combine = c) %do% {
    generate_max()
  }
}

cl <- makeCluster(detectCores() - 1)
clusterExport(cl, c("generate_max", "vec_size")) 
clusterSetRNGStream(cl, 1234)

parLapply_test <- function() {
  unlist(parLapply(cl, 1:n_iters, function(i) generate_max()))
}

benchmark_results <- microbenchmark(
  replicate = replicate_test(),
  foreach = foreach_test(),
  parLapply = parLapply_test(),
  times = 10
)

stopCluster(cl)

```
The table below contains the execution times for the different methods in milliseconds. 
| Method    | Min (ms) | Median (ms) | Mean (ms) | Max (ms) |
|-----------|---------|-------------|-----------|---------|
| **replicate**  | 4.49  | 4.67  | 5.03  | 6.74  |
| **foreach**    | 539.75  | 583.91  | 656.97  | 810.10  |
| **parLapply**  | 4.72  | 6.56  | 17.43  | 115.94  |

As seen in the table above, foreach was much slower with a mean time of 656.97, with parLapply having a mean of 17.43 milliseconds and replicate performing best with a mean of 5.03 milliseconds.
