#Time for replicate
start_replicate <- Sys.time()
replicate_results <- replicate(3, generate_max())
end_replicate <- Sys.time()
replicate_time <- end_replicate - start_replicate
#Time for foreach
start_foreach <- Sys.time()
iterat <- irnorm(3, 5)
foreach_results <- foreach(vec = iterat, .combine = c) %do% {
max(vec)
}
foreach_results <- foreach(vec = iterat, .combine = c) %do% {
max(vec)
}
############### Question 5 #############
library(parallel)
library(foreach)
library(iterators)
set.seed(1234)
generate_max <- function() {
max(rnorm(5))
}
# Time for replicate
replicate_time <- system.time({
replicate_results <- replicate(3, generate_max())
})
# Time for foreach
foreach_time <- system.time({
iterat <- irnorm(3, 5)
foreach_results <- foreach(vec = iterat, .combine = c) %do% {
max(vec)
}
})
# Time for parLapply
cl <- makeCluster(detectCores() - 1)
clusterSetRNGStream(cl, 1234)
parLapply_time <- system.time({
parLapply_results <- parLapply(cl, 1:3, function(i) generate_max())
})
clusterExport(cl, "generate_max")
parLapply_time <- system.time({
parLapply_results <- parLapply(cl, 1:3, function(i) generate_max())
})
stopCluster(cl)
# Results
print(paste("Replicate time:", replicate_time["elapsed"]))
print(paste("Foreach time:", foreach_time["elapsed"]))
print(paste("parLapply time:", parLapply_time["elapsed"]))
# Results
print(replicate_time)
print(foreach_time)
print(parLapply_time)
parLapply_time <- system.time({
parLapply_results <- parLapply(cl, 1:1000, function(i) generate_max())
})
############### Question 5 #############
library(parallel)
library(foreach)
library(iterators)
library(microbenchmark)
set.seed(1234)
n_iters <- 1000
vec_size <- 5
generate_max <- function() {
max(rnorm(vec_size))
}
replicate_test <- function() {
replicate(n_iters, generate_max())
}
foreach_test <- function() {
foreach(i = 1:n_iters, .combine = c) %do% {
generate_max()
}
}
cl <- makeCluster(detectCores() - 1)
clusterExport(cl, c("generate_max", "vec_size"))
clusterSetRNGStream(cl, 1234)
parLapply_test <- function() {
unlist(parLapply(cl, 1:n_iters, function(i) generate_max()))
}
benchmark_results <- microbenchmark(
replicate = replicate_test(),
foreach = foreach_test(),
parLapply = parLapply_test(),
times = 10
)
stopCluster(cl)
print(benchmark_results)
library(foreach)
library(doParallel)
library(MASS)
library(boot)
library(iterators)
library(parallel)
library(microbenchmark)
library(knitr)
numCores = detectCores() -1
cl <- makeCluster(numCores)
registerDoParallel(numCores)
n <- 100
results <- foreach(i = 1:n, .combine = rbind, .packages = "stats") %dopar% {
sample_d <- rexp(100, rate = 1)
mean_s <- mean(sample_d)
var_s <- var(sample_d)
c(mean_s, var_s)
}
stopCluster(cl)
result_df <- as.data.frame(results)
colnames(result_df) <- c("Mean", "Variance")
head(result_df)
numCores <- detectCores() - 1
cl <- makeCluster(numCores)
registerDoParallel(cl)
numBootstraps <- 1000
chunkSize <- 100
#Parralel bootstrapping
system.time({
boot_parallel <- foreach(i = 1:numBootstraps, .combine = c, .packages = "MASS") %dopar% {
samp_med <- median(sample(galaxies, replace = TRUE))
samp_med
}
})
# Serial Bootstrapping
system.time({
boot_serial <- sapply(1:numBootstraps, function(i) median(sample(galaxies, replace = TRUE)))
})
# Chunked Parallel Bootstrapping
system.time({
boot_chunked <- foreach(i = 1:(numBootstraps/chunkSize), .combine = c, .packages = "MASS") %dopar% {
replicate(chunkSize, median(sample(galaxies, replace = TRUE)))
}
})
stopCluster(cl)
head(boot_parallel)
head(boot_serial)
head(boot_chunked)
chunkSize <- 1000
system.time({
boot_parallel <- foreach(i = 1:numBootstraps, .combine = c, .packages = "MASS") %dopar% {
samp_med <- median(sample(galaxies, replace = TRUE))
samp_med
}
})
library(foreach)
library(doParallel)
library(MASS)
library(boot)
library(iterators)
library(parallel)
library(microbenchmark)
library(knitr)
numCores = detectCores() -1
cl <- makeCluster(numCores)
registerDoParallel(numCores)
n <- 100
results <- foreach(i = 1:n, .combine = rbind, .packages = "stats") %dopar% {
sample_d <- rexp(100, rate = 1)
mean_s <- mean(sample_d)
var_s <- var(sample_d)
c(mean_s, var_s)
}
stopCluster(cl)
result_df <- as.data.frame(results)
colnames(result_df) <- c("Mean", "Variance")
head(result_df)
numCores <- detectCores() - 1
cl <- makeCluster(numCores)
registerDoParallel(cl)
numBootstraps <- 1000
chunkSize <- 100
#Parralel bootstrapping
system.time({
boot_parallel <- foreach(i = 1:numBootstraps, .combine = c, .packages = "MASS") %dopar% {
samp_med <- median(sample(galaxies, replace = TRUE))
samp_med
}
})
# Serial Bootstrapping
system.time({
boot_serial <- sapply(1:numBootstraps, function(i) median(sample(galaxies, replace = TRUE)))
})
# Chunked Parallel Bootstrapping
system.time({
boot_chunked <- foreach(i = 1:(numBootstraps/chunkSize), .combine = c, .packages = "MASS") %dopar% {
replicate(chunkSize, median(sample(galaxies, replace = TRUE)))
}
})
stopCluster(cl)
head(boot_parallel)
head(boot_serial)
head(boot_chunked)
numCores <- detectCores() - 1
cl <- makeCluster(numCores)
registerDoParallel(cl)
numBootstraps <- 1000
chunkSize <- 1000
system.time({
boot_parallel <- foreach(i = 1:numBootstraps, .combine = c, .packages = "MASS") %dopar% {
samp_med <- median(sample(galaxies, replace = TRUE))
samp_med
}
})
# Serial Bootstrapping
system.time({
boot_serial <- sapply(1:numBootstraps, function(i) median(sample(galaxies, replace = TRUE)))
})
# Chunked Parallel Bootstrapping
system.time({
boot_chunked <- foreach(i = 1:(numBootstraps/chunkSize), .combine = c, .packages = "MASS") %dopar% {
replicate(chunkSize, median(sample(galaxies, replace = TRUE)))
}
})
stopCluster(cl)
head(boot_parallel)
head(boot_serial)
head(boot_chunked)
numCores <- detectCores() - 1
cl <- makeCluster(numCores)
registerDoParallel(cl)
numBootstraps <- 10000
chunkSize <- 100
#Parralel bootstrapping
system.time({
boot_parallel <- foreach(i = 1:numBootstraps, .combine = c, .packages = "MASS") %dopar% {
samp_med <- median(sample(galaxies, replace = TRUE))
samp_med
}
})
# Serial Bootstrapping
system.time({
boot_serial <- sapply(1:numBootstraps, function(i) median(sample(galaxies, replace = TRUE)))
})
# Chunked Parallel Bootstrapping
system.time({
boot_chunked <- foreach(i = 1:(numBootstraps/chunkSize), .combine = c, .packages = "MASS") %dopar% {
replicate(chunkSize, median(sample(galaxies, replace = TRUE)))
}
})
stopCluster(cl)
head(boot_parallel)
head(boot_serial)
head(boot_chunked)
numCores <- detectCores() - 1
cl <- makeCluster(numCores)
registerDoParallel(cl)
numBootstraps <- 10000
chunkSize <- 1000
system.time({
boot_parallel <- foreach(i = 1:numBootstraps, .combine = c, .packages = "MASS") %dopar% {
samp_med <- median(sample(galaxies, replace = TRUE))
samp_med
}
})
# Serial Bootstrapping
system.time({
boot_serial <- sapply(1:numBootstraps, function(i) median(sample(galaxies, replace = TRUE)))
})
# Chunked Parallel Bootstrapping
system.time({
boot_chunked <- foreach(i = 1:(numBootstraps/chunkSize), .combine = c, .packages = "MASS") %dopar% {
replicate(chunkSize, median(sample(galaxies, replace = TRUE)))
}
})
stopCluster(cl)
head(boot_parallel)
head(boot_serial)
head(boot_chunked)
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)
boot_mean <- function(data, indices) {
return(mean(data[indices]))
}
set.seed(123)
n_sim <- 1000
n_samp <- 50
alpha <- 0.05
# Run simulations in parallel
results <- foreach(i = 1:n_sim, .combine = c, .packages = "boot") %dopar% {
samp_data <- rexp(n_samp, rate = 1)  # Mean is 1
boot_res <- boot(samp_data, statistic = boot_mean, R = 1000)
ci <- boot.ci(boot_res, type = "perc")$percent[4:5]
(ci[1] <= 1) & (ci[2] >= 1)
}
stopCluster(cl)
cov_prob <- mean(results)
print(paste("Estimated Coverage:", round(cov_prob, 3)))
library(foreach)
library(iterators)
set.seed(1000)
iterat <- irnorm(3, 5)
max_vals <- foreach(vec = iterat, .combine = c) %do% {
max(vec)
}
print(max_vals)
library(foreach)
library(iterators)
set.seed(1234)
iterat <- irnorm(3, 5)
max_vals <- foreach(vec = iterat, .combine = c) %do% {
max(vec)
}
print(max_vals)
library(parallel)
library(parallel)
library(foreach)
library(iterators)
library(microbenchmark)
set.seed(1234)
n_iters <- 1000
vec_size <- 5
generate_max <- function() {
max(rnorm(vec_size))
}
replicate_test <- function() {
replicate(n_iters, generate_max())
}
foreach_test <- function() {
foreach(i = 1:n_iters, .combine = c) %do% {
generate_max()
}
}
cl <- makeCluster(detectCores() - 1)
clusterExport(cl, c("generate_max", "vec_size"))
clusterSetRNGStream(cl, 1234)
parLapply_test <- function() {
unlist(parLapply(cl, 1:n_iters, function(i) generate_max()))
}
benchmark_results <- microbenchmark(
replicate = replicate_test(),
foreach = foreach_test(),
parLapply = parLapply_test(),
times = 10
)
stopCluster(cl)
library(foreach)
library(iterators)
set.seed(1234)
iter_list <- as.list(irnorm(3, 5))
library(foreach)
library(iterators)
set.seed(1234)
# Create an iterator that generates 3 vectors, each with 5 normally distributed values
iterat <- irnorm(3, 5)
# Use foreach to iterate over the generated vectors
max_vals <- foreach(vec = iterat, .combine = c) %do% {
max(vec)  # Find the max in each vector
}
system.time(as.list(irnorm(3, 5)))
library(foreach)
library(iterators)
set.seed(1234)
# Create the iterator
iterat <- irnorm(3, 5)
# Use foreach to iterate over the extracted elements
max_vals <- foreach(vec = iter(iterat), .combine = c) %do% {
max(vec)
}
registerDoParallel(cores = 1)  # Forces single-threaded execution
system.time(as.list(irnorm(3, 5)))
packageVersion("iterators")
set.seed(1234)
iter_list <- iter(replicate(3, rnorm(5), simplify = FALSE))
max_vals <- foreach(vec = iter_list, .combine = c) %do% {
max(vec)
}
print(max_vals)
set.seed(1234)
# Generate list of 3 vectors, each containing 5 random numbers
iter_list <- iter(replicate(3, rnorm(5), simplify = FALSE))
# Use foreach properly
max_vals <- foreach(vec = iter_list, .combine = c) %do% {
print(vec)  # Debug: Print each vector
max(vec)    # Compute max value
}
# Print final result
print(max_vals)
set.seed(1234)
# Generate list of 3 vectors, each containing 5 random numbers
iter_list <- iter(replicate(3, rnorm(5), simplify = FALSE))
# Use foreach properly
max_vals <- foreach(vec = iter_list, .combine = c) %do% {
print(vec)  # Debug: Print each vector
max(vec)    # Compute max value
}
# Print final result
print(max_vals)
iter_list
set.seed(1234)
# Create an iterator (same as before)
iter_list <- iter(replicate(3, rnorm(5), simplify = FALSE))
# Manually extract elements from the iterator
vec1 <- nextElem(iter_list)
vec2 <- nextElem(iter_list)
set.seed(1234)
# Create the iterator for 3 vectors, each with 5 random numbers
iter_list <- iter(replicate(3, rnorm(5), simplify = FALSE))
# Convert the entire iterator to a list (this consumes the iterator)
vec_list <- as.list(iter_list)
# Now use foreach on the extracted list
max_vals <- foreach(vec = vec_list, .combine = c) %do% {
max(vec)  # Find the max in each vector
}
# Print final results
print(max_vals)
?irnorm()
set.seed(1234)
iterat <- irnorm(3, count=5)
max_vals <- foreach(vec = iterat, .combine = c) %do% {
max(vec)
}
print(max_vals)
max_vals <- foreach(vec = iterat, .combine = c) %do% {
max(vec)
}
print(max_vals)
it <- irnorm(3, count=5)
nextElem(it)
set.seed(1234)
# Create an iterator that generates 3 vectors of 5 random numbers each
it <- irnorm(3, count = 5)
# Convert the iterator to a list to fully extract the values
vec_list <- as.list(it)
# Now, use the vectors in foreach
library(foreach)
max_vals <- foreach(vec = vec_list, .combine = c) %do% {
max(vec)  # Find the max value for each vector
}
print(max_vals)
it
View(it)
set.seed(1234)
# Create an iterator that generates 3 vectors of 5 normally distributed random numbers each
it <- irnorm(3, 5)
# Use foreach to iterate over the vectors and find the largest value in each
largest_values <- foreach(i = it, .combine = c) %do% {
max(i)
}
it
it <- irnorm(3, 5) #recreate the iterator.
print(it$nextElem())
print(it$nextElem())
print(it$nextElem())
# Use foreach to iterate over the vectors and find the largest value in each
largest_values <- foreach(i = it, .combine = c) %do% {
max(i)
}
set.seed(1234)
# Create an iterator that generates 3 vectors of 5 normally distributed random numbers each
it <- irnorm(3, 5)
# Use foreach to iterate over the vectors and find the largest value in each
largest_values <- foreach(i = it, .combine = c) %do% {
max(i)
}
update.packages(c("foreach", "iterators"))
R.version.string
set.seed(1234)
# Create an iterator that generates 3 vectors of 5 normally distributed random numbers each
it <- irnorm(3, 5)
library(foreach)
library(iterators)
set.seed(1234)
# Create an iterator that generates 3 vectors of 5 normally distributed random numbers each
it <- irnorm(3, 5)
# Use foreach to iterate over the vectors and find the largest value in each
largest_values <- foreach(i = it, .combine = c) %do% {
max(i)
}
cl <- makeCluster(2)
library(foreach)
library(iterators)
library(doParallel)
library(knitr)
cl <- makeCluster(2)
registerDoParallel(cl)
set.seed(1234)
it <- irnorm(3, 5)
largest_values <- foreach(vec = irnorm(n = 5, count = 3), .combine = c) %do% {
max(vec)
}
results <- data.frame(MaxValues = max_values)
library(foreach)
library(iterators)
library(doParallel)
library(knitr)
cl <- makeCluster(2)
registerDoParallel(cl)
set.seed(1234)
it <- irnorm(3, 5)
max_values <- foreach(vec = irnorm(n = 5, count = 3), .combine = c) %do% {
max(vec)
}
results <- data.frame(MaxValues = max_values)
stopCluster(cl)
kable(results)
library(parallel)
library(doParallel)
library(parallel)
library(foreach)
numCores = detectCores() -1
cl <- makeCluster(numCores)
registerDoParallel(cl)
n <- 100
results <- foreach(i = 1:n, .combine = rbind, .packages = "stats") %dopar% {
sample_d <- rexp(100, rate = 1)
mean_s <- mean(sample_d)
var_s <- var(sample_d)
c(mean_s, var_s)
}
stopCluster(cl)
result_df <- as.data.frame(results)
colnames(result_df) <- c("Mean", "Variance")
head(result_df)
