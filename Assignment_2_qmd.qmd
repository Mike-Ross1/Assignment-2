---
title: "Assignment 2: Parallel Computing"
format: html
execute:
  warning: false
  message: false
---

## Packages

```{r}
library(foreach)
library(doParallel)
library(MASS)
library(boot)
library(iterators)
library(parallel)
library(microbenchmark)
library(knitr)

```

## Question 1

```{r}
numCores = detectCores() -1
cl <- makeCluster(numCores)
registerDoParallel(cl)
n <- 100

results <- foreach(i = 1:n, .combine = rbind, .packages = "stats") %dopar% {
  sample_d <- rexp(100, rate = 1)
  mean_s <- mean(sample_d)
  var_s <- var(sample_d)
  c(mean_s, var_s)
}
stopCluster(cl)

result_df <- as.data.frame(results)
colnames(result_df) <- c("Mean", "Variance")
head(result_df)

```

## Question 2

First setting the number of bootstrap samples = 1000 and trying chunk sizes of 100 and 1000 respectively. Note that the first few results from the bootstrap are displayed to show that they are yeilding plausible output.
```{r}
numCores <- detectCores() - 1
cl <- makeCluster(numCores)
registerDoParallel(cl)

numBootstraps <- 1000
chunkSize <- 100

#Parralel bootstrapping
system.time({
  boot_parallel <- foreach(i = 1:numBootstraps, .combine = c, .packages = "MASS") %dopar% {
    samp_med <- median(sample(galaxies, replace = TRUE))
    samp_med
  }
})

# Serial Bootstrapping
system.time({
  boot_serial <- sapply(1:numBootstraps, function(i) median(sample(galaxies, replace = TRUE)))
})

# Chunked Parallel Bootstrapping
system.time({
  boot_chunked <- foreach(i = 1:(numBootstraps/chunkSize), .combine = c, .packages = "MASS") %dopar% {
    replicate(chunkSize, median(sample(galaxies, replace = TRUE))) 
  }
})

stopCluster(cl)

head(boot_parallel)
head(boot_serial)
head(boot_chunked)
numCores <- detectCores() - 1
cl <- makeCluster(numCores)
registerDoParallel(cl)

numBootstraps <- 1000
chunkSize <- 100

system.time({
  boot_parallel <- foreach(i = 1:numBootstraps, .combine = c, .packages = "MASS") %dopar% {
    samp_med <- median(sample(galaxies, replace = TRUE))
    samp_med
  }
})

# Serial Bootstrapping
system.time({
  boot_serial <- sapply(1:numBootstraps, function(i) median(sample(galaxies, replace = TRUE)))
})

# Chunked Parallel Bootstrapping
system.time({
  boot_chunked <- foreach(i = 1:(numBootstraps/chunkSize), .combine = c, .packages = "MASS") %dopar% {
    replicate(chunkSize, median(sample(galaxies, replace = TRUE)))
  }
})

stopCluster(cl)

head(boot_parallel)
head(boot_serial)
head(boot_chunked)

```

Now setting the number of bootstrap samples = 10000 and testing across the same chunk sizes.
```{r echo=FALSE}
numCores <- detectCores() - 1
cl <- makeCluster(numCores)
registerDoParallel(cl)

numBootstraps <- 10000
chunkSize <- 100

#Parralel bootstrapping
system.time({
  boot_parallel <- foreach(i = 1:numBootstraps, .combine = c, .packages = "MASS") %dopar% {
    samp_med <- median(sample(galaxies, replace = TRUE))
    samp_med
  }
})

# Serial Bootstrapping
system.time({
  boot_serial <- sapply(1:numBootstraps, function(i) median(sample(galaxies, replace = TRUE)))
})

# Chunked Parallel Bootstrapping
system.time({
  boot_chunked <- foreach(i = 1:(numBootstraps/chunkSize), .combine = c, .packages = "MASS") %dopar% {
    replicate(chunkSize, median(sample(galaxies, replace = TRUE))) 
  }
})

stopCluster(cl)

numCores <- detectCores() - 1
cl <- makeCluster(numCores)
registerDoParallel(cl)

numBootstraps <- 10000
chunkSize <- 1000

system.time({
  boot_parallel <- foreach(i = 1:numBootstraps, .combine = c, .packages = "MASS") %dopar% {
    samp_med <- median(sample(galaxies, replace = TRUE))
    samp_med
  }
})

# Serial Bootstrapping
system.time({
  boot_serial <- sapply(1:numBootstraps, function(i) median(sample(galaxies, replace = TRUE)))
})

# Chunked Parallel Bootstrapping
system.time({
  boot_chunked <- foreach(i = 1:(numBootstraps/chunkSize), .combine = c, .packages = "MASS") %dopar% {
    replicate(chunkSize, median(sample(galaxies, replace = TRUE)))
  }
})

stopCluster(cl)

```

As seen above, the serial boot() function takes much longer than parallel execution with foreach.
Also, execution time is slightly reduced when going from chunk sizes of 100 to chunks sizes of 1000.
This suggests that overhead from data transfer dominates when using single-sample parallelism, but batching improves efficiency.

## Question 3

```{r}
cl <- makeCluster(detectCores() - 1)
registerDoParallel(cl)

boot_mean <- function(data, indices) {
  return(mean(data[indices]))
}

set.seed(123)
n_sim <- 1000
n_samp <- 50
alpha <- 0.05

# Run simulations in parallel
results <- foreach(i = 1:n_sim, .combine = c, .packages = "boot") %dopar% {
  samp_data <- rexp(n_samp, rate = 1)  # Mean is 1
  boot_res <- boot(samp_data, statistic = boot_mean, R = 1000)
  ci <- boot.ci(boot_res, type = "perc")$percent[4:5]
  (ci[1] <= 1) & (ci[2] >= 1)
}

stopCluster(cl)

cov_prob <- mean(results)
print(paste("Estimated Coverage:", round(cov_prob, 3)))

```

## Question 4

```{r,}
cl <- makeCluster(2)
registerDoParallel(cl)

set.seed(1234)


it <- irnorm(3, 5)
max_values <- foreach(vec = irnorm(n = 5, count = 3), .combine = c) %do% {
  max(vec)
}

results <- data.frame(MaxValues = max_values)
stopCluster(cl)
kable(results)
```

## Question 5

```{r,}
library(parallel)
library(foreach)
library(iterators)
library(microbenchmark)

set.seed(1234)

n_iters <- 1000
vec_size <- 5


generate_max <- function() {
  max(rnorm(vec_size))
}

replicate_test <- function() {
  replicate(n_iters, generate_max())
}

foreach_test <- function() {
  foreach(i = 1:n_iters, .combine = c) %do% {
    generate_max()
  }
}

cl <- makeCluster(detectCores() - 1)
clusterExport(cl, c("generate_max", "vec_size")) 
clusterSetRNGStream(cl, 1234)

parLapply_test <- function() {
  unlist(parLapply(cl, 1:n_iters, function(i) generate_max()))
}

benchmark_results <- microbenchmark(
  replicate = replicate_test(),
  foreach = foreach_test(),
  parLapply = parLapply_test(),
  times = 10
)

stopCluster(cl)

```
The table below contains the execution times for the different methods in milliseconds.

| Method      | Min (ms) | Median (ms) | Mean (ms) | Max (ms) |
| ----------- | -------- | ----------- | --------- | -------- |
| **replicate** | 4.49     | 4.67        | 5.03      | 6.74     |
| **foreach** | 539.75   | 583.91      | 656.97    | 810.10   |
| **parLapply** | 4.72     | 6.56        | 17.43     | 115.94   |

As seen in the table above, foreach was much slower with a mean time of 656.97, with parLapply having a mean of 17.43 milliseconds and replicate performing best with a mean of 5.03 milliseconds.
